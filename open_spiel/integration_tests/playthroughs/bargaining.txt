game: bargaining

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.IMPERFECT_INFORMATION
GameType.long_name = "Bargaining"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["discount", "instances_file", "max_turns", "prob_end", "symmetric"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = True
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "bargaining"
GameType.utility = Utility.GENERAL_SUM

NumDistinctActions() = 121
PolicyTensorShape() = [121]
MaxChanceOutcomes() = 42
GetParameters() = {discount=1.0,instances_file=,max_turns=10,prob_end=0.0,symmetric=True}
NumPlayers() = 2
MinUtility() = 0.0
MaxUtility() = 10.0
UtilitySum() = None
InformationStateTensorShape() = [309]
InformationStateTensorLayout() = TensorLayout.CHW
InformationStateTensorSize() = 309
ObservationTensorShape() = [93]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 93
MaxGameLength() = 10
ToString() = "bargaining()"

# State 0
# Initial chance node
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "Initial chance node"
InformationStateString(1) = "Initial chance node"
InformationStateTensor(0): zeros(309)
InformationStateTensor(1): zeros(309)
ObservationString(0) = "Initial chance node"
ObservationString(1) = "Initial chance node"
ObservationTensor(0): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(0, 0.025), (1, 0.025), (2, 0.025), (3, 0.025), (4, 0.025), (5, 0.025), (6, 0.025), (7, 0.025), (8, 0.025), (9, 0.025), (10, 0.025), (11, 0.025), (12, 0.025), (13, 0.025), (14, 0.025), (15, 0.025), (16, 0.025), (17, 0.025), (18, 0.025), (19, 0.025), (20, 0.025), (21, 0.025), (22, 0.025), (23, 0.025), (24, 0.025), (25, 0.025), (26, 0.025), (27, 0.025), (28, 0.025), (29, 0.025), (30, 0.025), (31, 0.025), (32, 0.025), (33, 0.025), (34, 0.025), (35, 0.025), (36, 0.025), (37, 0.025), (38, 0.025), (39, 0.025)]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]
StringLegalActions() = ["Chance outcome 0", "Chance outcome 1", "Chance outcome 2", "Chance outcome 3", "Chance outcome 4", "Chance outcome 5", "Chance outcome 6", "Chance outcome 7", "Chance outcome 8", "Chance outcome 9", "Chance outcome 10", "Chance outcome 11", "Chance outcome 12", "Chance outcome 13", "Chance outcome 14", "Chance outcome 15", "Chance outcome 16", "Chance outcome 17", "Chance outcome 18", "Chance outcome 19", "Chance outcome 20", "Chance outcome 21", "Chance outcome 22", "Chance outcome 23", "Chance outcome 24", "Chance outcome 25", "Chance outcome 26", "Chance outcome 27", "Chance outcome 28", "Chance outcome 29", "Chance outcome 30", "Chance outcome 31", "Chance outcome 32", "Chance outcome 33", "Chance outcome 34", "Chance outcome 35", "Chance outcome 36", "Chance outcome 37", "Chance outcome 38", "Chance outcome 39"]

# Apply action "Chance outcome 33"
action: 33

# State 1
# Pool:    1 3 1
# P0 vals: 2 2 2
# P1 vals: 10 0 0
# Agreement reached? 0
IsTerminal() = False
History() = [33]
HistoryString() = "33"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "Pool: 1 3 1\nMy values: 2 2 2\nAgreement reached? 0\n"
InformationStateString(1) = "Pool: 1 3 1\nMy values: 10 0 0\nAgreement reached? 0\n"
InformationStateTensor(0): binvec(309, 0x100181e181c0380700000000000000000000000000000000000000000000000000000000000000)
InformationStateTensor(1): binvec(309, 0x100181e181ffe00400000000000000000000000000000000000000000000000000000000000000)
ObservationString(0) = "Pool: 1 3 1\nMy values: 2 2 2\nAgreement reached? 0\nNumber of offers: 0\n"
ObservationString(1) = "Pool: 1 3 1\nMy values: 10 0 0\nAgreement reached? 0\nNumber of offers: 0\n"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 8, 9, 15, 16, 21, 22, 36, 37, 43, 44, 49, 50, 54, 55]
StringLegalActions() = ["Offer: 0 0 0", "Offer: 1 0 0", "Offer: 0 1 0", "Offer: 1 1 0", "Offer: 0 2 0", "Offer: 1 2 0", "Offer: 0 3 0", "Offer: 1 3 0", "Offer: 0 0 1", "Offer: 1 0 1", "Offer: 0 1 1", "Offer: 1 1 1", "Offer: 0 2 1", "Offer: 1 2 1", "Offer: 0 3 1", "Offer: 1 3 1"]

# Apply action "Offer: 0 3 1"
action: 54

# State 2
# Pool:    1 3 1
# P0 vals: 2 2 2
# P1 vals: 10 0 0
# Agreement reached? 0
# P1 offers: Offer: 0 3 1
IsTerminal() = False
History() = [33, 54]
HistoryString() = "33, 54"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "Pool: 1 3 1\nMy values: 2 2 2\nAgreement reached? 0\nP1 offers: Offer: 0 3 1\n"
InformationStateString(1) = "Pool: 1 3 1\nMy values: 10 0 0\nAgreement reached? 0\nP1 offers: Offer: 0 3 1\n"
InformationStateTensor(0): binvec(309, 0x80181e181c038070080f0c0000000000000000000000000000000000000000000000000000000)
InformationStateTensor(1): binvec(309, 0x80181e181ffe0040080f0c0000000000000000000000000000000000000000000000000000000)
ObservationString(0) = "Pool: 1 3 1\nMy values: 2 2 2\nAgreement reached? 0\nNumber of offers: 1\nP0 offers: Offer: 0 3 1\n"
ObservationString(1) = "Pool: 1 3 1\nMy values: 10 0 0\nAgreement reached? 0\nNumber of offers: 1\nP0 offers: Offer: 0 3 1\n"
ObservationTensor(0): ◯◉◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 8, 9, 15, 16, 21, 22, 36, 37, 43, 44, 49, 50, 54, 55, 120]
StringLegalActions() = ["Offer: 0 0 0", "Offer: 1 0 0", "Offer: 0 1 0", "Offer: 1 1 0", "Offer: 0 2 0", "Offer: 1 2 0", "Offer: 0 3 0", "Offer: 1 3 0", "Offer: 0 0 1", "Offer: 1 0 1", "Offer: 0 1 1", "Offer: 1 1 1", "Offer: 0 2 1", "Offer: 1 2 1", "Offer: 0 3 1", "Offer: 1 3 1", "Agree"]

# Apply action "Agree"
action: 120

# State 3
# Pool:    1 3 1
# P0 vals: 2 2 2
# P1 vals: 10 0 0
# Agreement reached? 1
# P1 offers: Offer: 0 3 1
IsTerminal() = True
History() = [33, 54, 120]
HistoryString() = "33, 54, 120"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "Pool: 1 3 1\nMy values: 2 2 2\nAgreement reached? 1\nP1 offers: Offer: 0 3 1\n"
InformationStateString(1) = "Pool: 1 3 1\nMy values: 10 0 0\nAgreement reached? 1\nP1 offers: Offer: 0 3 1\n"
InformationStateTensor(0): binvec(309, 0x180181e181c038070080f0c0000000000000000000000000000000000000000000000000000000)
InformationStateTensor(1): binvec(309, 0x180181e181ffe0040080f0c0000000000000000000000000000000000000000000000000000000)
ObservationString(0) = "Pool: 1 3 1\nMy values: 2 2 2\nAgreement reached? 1\nNumber of offers: 1\nP0 offers: Offer: 0 3 1\n"
ObservationString(1) = "Pool: 1 3 1\nMy values: 10 0 0\nAgreement reached? 1\nNumber of offers: 1\nP0 offers: Offer: 0 3 1\n"
ObservationTensor(0): ◉◉◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯
ObservationTensor(1): ◉◉◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯
Rewards() = [2, 0]
Returns() = [2, 0]
