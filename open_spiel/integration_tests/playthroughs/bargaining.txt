game: bargaining

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.IMPERFECT_INFORMATION
GameType.long_name = "Bargaining"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["discount", "instances_file", "max_turns", "prob_end", "symmetric"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = True
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "bargaining"
GameType.utility = Utility.GENERAL_SUM

NumDistinctActions() = 121
PolicyTensorShape() = [121]
MaxChanceOutcomes() = 22
GetParameters() = {discount=1.0,instances_file=,max_turns=10,prob_end=0.0,symmetric=True}
NumPlayers() = 2
MinUtility() = 0.0
MaxUtility() = 10.0
UtilitySum() = None
InformationStateTensorShape() = [309]
InformationStateTensorLayout() = TensorLayout.CHW
InformationStateTensorSize() = 309
ObservationTensorShape() = [93]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 93
MaxGameLength() = 10
ToString() = "bargaining()"

# State 0
# Initial chance node
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "Initial chance node"
InformationStateString(1) = "Initial chance node"
InformationStateTensor(0): zeros(309)
InformationStateTensor(1): zeros(309)
ObservationString(0) = "Initial chance node"
ObservationString(1) = "Initial chance node"
ObservationTensor(0): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(0, 0.05), (1, 0.05), (2, 0.05), (3, 0.05), (4, 0.05), (5, 0.05), (6, 0.05), (7, 0.05), (8, 0.05), (9, 0.05), (10, 0.05), (11, 0.05), (12, 0.05), (13, 0.05), (14, 0.05), (15, 0.05), (16, 0.05), (17, 0.05), (18, 0.05), (19, 0.05)]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
StringLegalActions() = ["Chance outcome 0", "Chance outcome 1", "Chance outcome 2", "Chance outcome 3", "Chance outcome 4", "Chance outcome 5", "Chance outcome 6", "Chance outcome 7", "Chance outcome 8", "Chance outcome 9", "Chance outcome 10", "Chance outcome 11", "Chance outcome 12", "Chance outcome 13", "Chance outcome 14", "Chance outcome 15", "Chance outcome 16", "Chance outcome 17", "Chance outcome 18", "Chance outcome 19"]

# Apply action "Chance outcome 3"
action: 3

# State 1
# Pool:    1 4 1
# P0 vals: 4 1 2
# P1 vals: 2 2 0
# Agreement reached? 0
IsTerminal() = False
History() = [3]
HistoryString() = "3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\n"
InformationStateString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\n"
InformationStateTensor(0): binvec(309, 0x100181f181f0300700000000000000000000000000000000000000000000000000000000000000)
InformationStateTensor(1): binvec(309, 0x100181f181c0380400000000000000000000000000000000000000000000000000000000000000)
ObservationString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nNumber of offers: 0\n"
ObservationString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nNumber of offers: 0\n"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 8, 9, 15, 16, 21, 22, 26, 27, 36, 37, 43, 44, 49, 50, 54, 55, 58, 59]
StringLegalActions() = ["Offer: 0 0 0", "Offer: 1 0 0", "Offer: 0 1 0", "Offer: 1 1 0", "Offer: 0 2 0", "Offer: 1 2 0", "Offer: 0 3 0", "Offer: 1 3 0", "Offer: 0 4 0", "Offer: 1 4 0", "Offer: 0 0 1", "Offer: 1 0 1", "Offer: 0 1 1", "Offer: 1 1 1", "Offer: 0 2 1", "Offer: 1 2 1", "Offer: 0 3 1", "Offer: 1 3 1", "Offer: 0 4 1", "Offer: 1 4 1"]

# Apply action "Offer: 0 2 0"
action: 15

# State 2
# Pool:    1 4 1
# P0 vals: 4 1 2
# P1 vals: 2 2 0
# Agreement reached? 0
# P1 offers: Offer: 0 2 0
IsTerminal() = False
History() = [3, 15]
HistoryString() = "3, 15"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\n"
InformationStateString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\n"
InformationStateTensor(0): binvec(309, 0x80181f181f030070080e080000000000000000000000000000000000000000000000000000000)
InformationStateTensor(1): binvec(309, 0x80181f181c038040080e080000000000000000000000000000000000000000000000000000000)
ObservationString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nNumber of offers: 1\nP0 offers: Offer: 0 2 0\n"
ObservationString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nNumber of offers: 1\nP0 offers: Offer: 0 2 0\n"
ObservationTensor(0): ◯◉◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 8, 9, 15, 16, 21, 22, 26, 27, 36, 37, 43, 44, 49, 50, 54, 55, 58, 59, 120]
StringLegalActions() = ["Offer: 0 0 0", "Offer: 1 0 0", "Offer: 0 1 0", "Offer: 1 1 0", "Offer: 0 2 0", "Offer: 1 2 0", "Offer: 0 3 0", "Offer: 1 3 0", "Offer: 0 4 0", "Offer: 1 4 0", "Offer: 0 0 1", "Offer: 1 0 1", "Offer: 0 1 1", "Offer: 1 1 1", "Offer: 0 2 1", "Offer: 1 2 1", "Offer: 0 3 1", "Offer: 1 3 1", "Offer: 0 4 1", "Offer: 1 4 1", "Agree"]

# Apply action "Offer: 0 3 1"
action: 54

# State 3
# Pool:    1 4 1
# P0 vals: 4 1 2
# P1 vals: 2 2 0
# Agreement reached? 0
# P1 offers: Offer: 0 2 0
# P0 offers: Offer: 0 3 1
IsTerminal() = False
History() = [3, 15, 54]
HistoryString() = "3, 15, 54"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\n"
InformationStateString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\n"
InformationStateTensor(0): binvec(309, 0x40181f181f030070080e08080f0c0000000000000000000000000000000000000000000000000)
InformationStateTensor(1): binvec(309, 0x40181f181c038040080e08080f0c0000000000000000000000000000000000000000000000000)
ObservationString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nNumber of offers: 2\nP1 offers: Offer: 0 3 1\n"
ObservationString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nNumber of offers: 2\nP1 offers: Offer: 0 3 1\n"
ObservationTensor(0): ◯◯◉◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯
ObservationTensor(1): ◯◯◉◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 8, 9, 15, 16, 21, 22, 26, 27, 36, 37, 43, 44, 49, 50, 54, 55, 58, 59, 120]
StringLegalActions() = ["Offer: 0 0 0", "Offer: 1 0 0", "Offer: 0 1 0", "Offer: 1 1 0", "Offer: 0 2 0", "Offer: 1 2 0", "Offer: 0 3 0", "Offer: 1 3 0", "Offer: 0 4 0", "Offer: 1 4 0", "Offer: 0 0 1", "Offer: 1 0 1", "Offer: 0 1 1", "Offer: 1 1 1", "Offer: 0 2 1", "Offer: 1 2 1", "Offer: 0 3 1", "Offer: 1 3 1", "Offer: 0 4 1", "Offer: 1 4 1", "Agree"]

# Apply action "Offer: 0 3 1"
action: 54

# State 4
# Pool:    1 4 1
# P0 vals: 4 1 2
# P1 vals: 2 2 0
# Agreement reached? 0
# P1 offers: Offer: 0 2 0
# P0 offers: Offer: 0 3 1
# P1 offers: Offer: 0 3 1
IsTerminal() = False
History() = [3, 15, 54, 54]
HistoryString() = "3, 15, 54, 54"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\nP1 offers: Offer: 0 3 1\n"
InformationStateString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\nP1 offers: Offer: 0 3 1\n"
InformationStateTensor(0): binvec(309, 0x20181f181f030070080e08080f0c080f0c0000000000000000000000000000000000000000000)
InformationStateTensor(1): binvec(309, 0x20181f181c038040080e08080f0c080f0c0000000000000000000000000000000000000000000)
ObservationString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nNumber of offers: 3\nP0 offers: Offer: 0 3 1\n"
ObservationString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nNumber of offers: 3\nP0 offers: Offer: 0 3 1\n"
ObservationTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◉◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 8, 9, 15, 16, 21, 22, 26, 27, 36, 37, 43, 44, 49, 50, 54, 55, 58, 59, 120]
StringLegalActions() = ["Offer: 0 0 0", "Offer: 1 0 0", "Offer: 0 1 0", "Offer: 1 1 0", "Offer: 0 2 0", "Offer: 1 2 0", "Offer: 0 3 0", "Offer: 1 3 0", "Offer: 0 4 0", "Offer: 1 4 0", "Offer: 0 0 1", "Offer: 1 0 1", "Offer: 0 1 1", "Offer: 1 1 1", "Offer: 0 2 1", "Offer: 1 2 1", "Offer: 0 3 1", "Offer: 1 3 1", "Offer: 0 4 1", "Offer: 1 4 1", "Agree"]

# Apply action "Offer: 0 0 0"
action: 0

# State 5
# Pool:    1 4 1
# P0 vals: 4 1 2
# P1 vals: 2 2 0
# Agreement reached? 0
# P1 offers: Offer: 0 2 0
# P0 offers: Offer: 0 3 1
# P1 offers: Offer: 0 3 1
# P0 offers: Offer: 0 0 0
IsTerminal() = False
History() = [3, 15, 54, 54, 0]
HistoryString() = "3, 15, 54, 54, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\nP1 offers: Offer: 0 3 1\nP0 offers: Offer: 0 0 0\n"
InformationStateString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\nP1 offers: Offer: 0 3 1\nP0 offers: Offer: 0 0 0\n"
InformationStateTensor(0): binvec(309, 0x10181f181f030070080e08080f0c080f0c0808080000000000000000000000000000000000000)
InformationStateTensor(1): binvec(309, 0x10181f181c038040080e08080f0c080f0c0808080000000000000000000000000000000000000)
ObservationString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nNumber of offers: 4\nP1 offers: Offer: 0 0 0\n"
ObservationString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nNumber of offers: 4\nP1 offers: Offer: 0 0 0\n"
ObservationTensor(0): ◯◯◯◯◉◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◉◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 8, 9, 15, 16, 21, 22, 26, 27, 36, 37, 43, 44, 49, 50, 54, 55, 58, 59, 120]
StringLegalActions() = ["Offer: 0 0 0", "Offer: 1 0 0", "Offer: 0 1 0", "Offer: 1 1 0", "Offer: 0 2 0", "Offer: 1 2 0", "Offer: 0 3 0", "Offer: 1 3 0", "Offer: 0 4 0", "Offer: 1 4 0", "Offer: 0 0 1", "Offer: 1 0 1", "Offer: 0 1 1", "Offer: 1 1 1", "Offer: 0 2 1", "Offer: 1 2 1", "Offer: 0 3 1", "Offer: 1 3 1", "Offer: 0 4 1", "Offer: 1 4 1", "Agree"]

# Apply action "Offer: 1 1 1"
action: 44

# State 6
# Pool:    1 4 1
# P0 vals: 4 1 2
# P1 vals: 2 2 0
# Agreement reached? 0
# P1 offers: Offer: 0 2 0
# P0 offers: Offer: 0 3 1
# P1 offers: Offer: 0 3 1
# P0 offers: Offer: 0 0 0
# P1 offers: Offer: 1 1 1
IsTerminal() = False
History() = [3, 15, 54, 54, 0, 44]
HistoryString() = "3, 15, 54, 54, 0, 44"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\nP1 offers: Offer: 0 3 1\nP0 offers: Offer: 0 0 0\nP1 offers: Offer: 1 1 1\n"
InformationStateString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\nP1 offers: Offer: 0 3 1\nP0 offers: Offer: 0 0 0\nP1 offers: Offer: 1 1 1\n"
InformationStateTensor(0): binvec(309, 0x8181f181f030070080e08080f0c080f0c0808080c0c0c0000000000000000000000000000000)
InformationStateTensor(1): binvec(309, 0x8181f181c038040080e08080f0c080f0c0808080c0c0c0000000000000000000000000000000)
ObservationString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nNumber of offers: 5\nP0 offers: Offer: 1 1 1\n"
ObservationString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nNumber of offers: 5\nP0 offers: Offer: 1 1 1\n"
ObservationTensor(0): ◯◯◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 8, 9, 15, 16, 21, 22, 26, 27, 36, 37, 43, 44, 49, 50, 54, 55, 58, 59, 120]
StringLegalActions() = ["Offer: 0 0 0", "Offer: 1 0 0", "Offer: 0 1 0", "Offer: 1 1 0", "Offer: 0 2 0", "Offer: 1 2 0", "Offer: 0 3 0", "Offer: 1 3 0", "Offer: 0 4 0", "Offer: 1 4 0", "Offer: 0 0 1", "Offer: 1 0 1", "Offer: 0 1 1", "Offer: 1 1 1", "Offer: 0 2 1", "Offer: 1 2 1", "Offer: 0 3 1", "Offer: 1 3 1", "Offer: 0 4 1", "Offer: 1 4 1", "Agree"]

# Apply action "Offer: 0 2 0"
action: 15

# State 7
# Apply action "Offer: 0 2 1"
action: 49

# State 8
# Apply action "Offer: 0 4 1"
action: 58

# State 9
# Apply action "Offer: 1 0 1"
action: 37

# State 10
# Apply action "Offer: 0 1 0"
action: 8

# State 11
# Pool:    1 4 1
# P0 vals: 4 1 2
# P1 vals: 2 2 0
# Agreement reached? 0
# P1 offers: Offer: 0 2 0
# P0 offers: Offer: 0 3 1
# P1 offers: Offer: 0 3 1
# P0 offers: Offer: 0 0 0
# P1 offers: Offer: 1 1 1
# P0 offers: Offer: 0 2 0
# P1 offers: Offer: 0 2 1
# P0 offers: Offer: 0 4 1
# P1 offers: Offer: 1 0 1
# P0 offers: Offer: 0 1 0
IsTerminal() = True
History() = [3, 15, 54, 54, 0, 44, 15, 49, 58, 37, 8]
HistoryString() = "3, 15, 54, 54, 0, 44, 15, 49, 58, 37, 8"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\nP1 offers: Offer: 0 3 1\nP0 offers: Offer: 0 0 0\nP1 offers: Offer: 1 1 1\nP0 offers: Offer: 0 2 0\nP1 offers: Offer: 0 2 1\nP0 offers: Offer: 0 4 1\nP1 offers: Offer: 1 0 1\nP0 offers: Offer: 0 1 0\n"
InformationStateString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nP1 offers: Offer: 0 2 0\nP0 offers: Offer: 0 3 1\nP1 offers: Offer: 0 3 1\nP0 offers: Offer: 0 0 0\nP1 offers: Offer: 1 1 1\nP0 offers: Offer: 0 2 0\nP1 offers: Offer: 0 2 1\nP0 offers: Offer: 0 4 1\nP1 offers: Offer: 1 0 1\nP0 offers: Offer: 0 1 0\n"
InformationStateTensor(0): binvec(309, 0x581f181f030070080e08080f0c080f0c0808080c0c0c080e08080e0c080f8c0c080c080c080)
InformationStateTensor(1): binvec(309, 0x581f181c038040080e08080f0c080f0c0808080c0c0c080e08080e0c080f8c0c080c080c080)
ObservationString(0) = "Pool: 1 4 1\nMy values: 4 1 2\nAgreement reached? 0\nNumber of offers: 10\nP1 offers: Offer: 0 1 0\n"
ObservationString(1) = "Pool: 1 4 1\nMy values: 2 2 0\nAgreement reached? 0\nNumber of offers: 10\nP1 offers: Offer: 0 1 0\n"
ObservationTensor(0): ◯◯◯◯◯◯◯◯◯◯◉◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◉◯◉◉◯◯◯◯◯◯◉◉◉◉◉◯◯◯◉◉◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
